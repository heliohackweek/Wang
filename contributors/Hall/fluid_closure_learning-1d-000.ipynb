{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from numpy import sqrt, cos, sin, pi\n",
    "from numpy.fft import fft, ifft, rfft, irfft\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1d closure ([Hammett & Perkins 1990 PRL](https://w3.pppl.gov/~hammett/refs/1990/Hammett_90_PRL_Landau_fluid_corrected.pdf)) written in the Fourier space:\n",
    "$$\\tilde{q}_{k}=-n_{0}\\chi_{1}\\frac{\\sqrt{2}v_{t}}{\\left|k\\right|}ik\\tilde{T}_{k}$$\n",
    "where $\\tilde{q}_k$ is the heatflux in the k-space,  $\\tilde{T}_k$ is the temperature fluctuation in the k-space, $\\chi_{1}=\\frac{2}{\\sqrt{\\pi}}$, $n_0$ is the background density, $v_t=\\sqrt{T_0/m}$ is the thermal speed.\n",
    "- input/feature: $\\tilde{T}$ in the real-space\n",
    "- output/label: $\\tilde{q}$ in the real-space computed (after fft/ifft) from the closue using $\\tilde{T}$\n",
    "- reference: [Ma+2020POP](http://arxiv.org/abs/1909.11509)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples_train = 10000\n",
    "nsamples_test  = 100\n",
    "nsamples       = nsamples_train + nsamples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physics parameters that define the input (feature) and output (label)\n",
    "n0 = 1.\n",
    "vt = 1.\n",
    "chi1 = 2. / sqrt(pi)\n",
    "\n",
    "lx = 2. * pi\n",
    "nx = 128\n",
    "kmax = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     50
    ]
   },
   "outputs": [],
   "source": [
    "def make_modes(x, kmax, magnitude=1.):\n",
    "    \"\"\"Make many sinusoidal modes with random amplitudes and phases.\n",
    "\n",
    "    Args:\n",
    "        x: 1d spatial coordinates.\n",
    "        kmax: k = 1, 2, ..., kmax.\n",
    "\n",
    "    Returns:\n",
    "        modes: Superposition of all modes.\n",
    "    \"\"\"\n",
    "    A = np.random.random((kmax)) * magnitude\n",
    "    phi = np.random.random((kmax)) * pi * 2\n",
    "    modes = np.zeros_like(x)\n",
    "    for k in range(1, kmax):\n",
    "        A_k = A[k]\n",
    "        phi_k = phi[k]\n",
    "        modes += A_k * np.cos(k * x + phi_k)\n",
    "    return modes\n",
    "\n",
    "\n",
    "def make_training_data():\n",
    "    x = np.linspace(0, lx, nx)\n",
    "    k = np.fft.fftfreq(nx, d=lx/nx) * 2. * pi\n",
    "\n",
    "    T_all = []\n",
    "    q_all = []\n",
    "\n",
    "    coeff_q = -n0 * chi1 * sqrt(2) * vt * 1j * np.sign(k)\n",
    "\n",
    "    for isample in tqdm(range(nsamples)):\n",
    "        # Temperature flucutations in real space, T(x)\n",
    "        T = make_modes(x, kmax)\n",
    "        # Temperature fluctuations in Fourier spacer, T(k)\n",
    "        Tk = fft(T)\n",
    "        # heatflux fluctuation in Fourier space, q(k)\n",
    "        qk = coeff_q * Tk\n",
    "        # heatflux fluctuation in real space, q(x)\n",
    "        q = ifft(qk).real\n",
    "\n",
    "        # append real-space input/output of this sample\n",
    "        T_all.append(T)\n",
    "        q_all.append(q)\n",
    "\n",
    "    # convert to ndarray of shape (nsamples, nx)\n",
    "    T_all = np.array(T_all)\n",
    "    q_all = np.array(q_all)\n",
    "\n",
    "    return T_all, q_all\n",
    "\n",
    "\n",
    "def normalize(arr):\n",
    "    # all data have mean=0\n",
    "    # XXX use the same max\n",
    "    return arr / abs(arr).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10100/10100 [00:01<00:00, 5614.69it/s]\n"
     ]
    }
   ],
   "source": [
    "T, q = make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = normalize(T)\n",
    "q = normalize(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data   = T[:nsamples_train, ...]\n",
    "train_labels = q[:nsamples_train, ...]\n",
    "\n",
    "test_data    = T[nsamples_train:, ...]\n",
    "test_labels  = q[nsamples_train:, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create several models that we can compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "=================================================================\n",
      "Total params: 131,712\n",
      "Trainable params: 131,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dense model using Sequential Layer\n",
    "\n",
    "num_nodes = 256\n",
    "model1 = keras.Sequential([\n",
    "    layers.Dense(num_nodes,activation='relu',input_shape=(train_data.shape[1], )),\n",
    "    layers.Dense(num_nodes, activation='relu'),\n",
    "    layers.Dense(train_labels.shape[1], activation='linear')\n",
    "])\n",
    "model1.compile(loss='mse',optimizer=keras.optimizers.Adam(),metrics=['accuracy', 'mae', 'mse'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          33024       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128)          0           input_1[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 131,712\n",
      "Trainable params: 131,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dense model (with skip connections) using the functional API\n",
    "\n",
    "num_nodes= 256\n",
    "inputs   = keras.Input(shape=nx)\n",
    "layer1   = layers.Dense(num_nodes,activation='relu')(inputs)\n",
    "layer2   = layers.Dense(num_nodes,activation='relu')(layer1)\n",
    "skip1    = layers.Add()([layer1,layer2]) \n",
    "layer3   = layers.Dense(nx, activation='linear')(layer2)\n",
    "skip2    = layers.Add()([inputs,layer3])\n",
    "outputs  = skip2\n",
    "model2   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model2.compile(loss='mse',optimizer=keras.optimizers.Adam(),metrics=['accuracy', 'mae', 'mse'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 99; time total 44.9509s per-epoch 0.449509s:loss 2.0e-05; accuracy 9.2e-01; mae 3.3e-03; mse 2.0e-05; val_loss 1.3e-05; val_accuracy 9.1e-01; val_mae 2.9e-03; val_mse 1.3e-05\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100  # How many times we go through the entire dataset\n",
    "validation_split = 0.05  # fraction of data to be used as live validation\n",
    "\n",
    "# https://keras.io/guides/writing_your_own_callbacks/\n",
    "class PrintLogs(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.time_begin = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch >0 and (epoch+1) % 100 == 0:\n",
    "            info = ''\n",
    "            info += 'EPOCH {}'.format(epoch)\n",
    "            dt = time.time() - self.time_begin\n",
    "            dt_per_epoch = dt / (epoch + 1)\n",
    "            info +='; time total {:g}s per-epoch {:g}s:'.format(dt, dt_per_epoch)\n",
    "            log_epoch = [\n",
    "                '{} {:.1e}'.format(key, logs[key]) for key in logs.keys()\n",
    "            ]\n",
    "            info += '; '.join(log_epoch)\n",
    "            print(info)\n",
    "\n",
    "\n",
    "callbacks = [PrintLogs()]\n",
    "\n",
    "# https://keras.io/api/models/model_training_apis/#fit-method\n",
    "history = model1.fit(train_data,train_labels,epochs=EPOCHS,validation_split=validation_split,verbose=0,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 99; time total 44.6059s per-epoch 0.446059s:loss 4.6e-05; accuracy 8.9e-01; mae 4.8e-03; mse 4.6e-05; val_loss 8.3e-05; val_accuracy 8.2e-01; val_mae 7.2e-03; val_mse 8.3e-05\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_data,train_labels,epochs=EPOCHS,validation_split=validation_split,verbose=0,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.929158</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.902842</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.938105</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.902526</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.923368</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy       mae       mse  val_loss  val_accuracy   val_mae  \\\n",
       "95  0.000015  0.929158  0.002876  0.000015  0.000018         0.936  0.003299   \n",
       "96  0.000032  0.902842  0.004233  0.000032  0.000018         0.930  0.003304   \n",
       "97  0.000013  0.938105  0.002774  0.000013  0.000030         0.902  0.004132   \n",
       "98  0.000027  0.902526  0.003911  0.000027  0.000017         0.936  0.003165   \n",
       "99  0.000020  0.923368  0.003306  0.000020  0.000013         0.912  0.002857   \n",
       "\n",
       "     val_mse  epoch  \n",
       "95  0.000018     95  \n",
       "96  0.000018     96  \n",
       "97  0.000030     97  \n",
       "98  0.000017     98  \n",
       "99  0.000013     99  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the stats stored in the history object.\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3088d1ba9c2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history1' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_history(history, step=25):\n",
    "    fig = plt.figure(figsize=(12, 3))\n",
    "    hist = pd.DataFrame(history.history).iloc[::step]\n",
    "    hist['epoch'] = history.epoch[::step]\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.semilogy(hist['epoch'], hist['mae'], label='training')\n",
    "    plt.semilogy(hist['epoch'], hist['val_mae'], label='test', alpha=0.8)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error (mae)')\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.semilogy(hist['epoch'], hist['mse'], label='training')\n",
    "    plt.semilogy(hist['epoch'], hist['val_mse'], label='test', alpha=0.8)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error (mse)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "plot_history(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the overall scores of the model\n",
    "scores = model.evaluate(test_data, test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare truth and prediction for one or more test samples\n",
    "for itest in range(1):\n",
    "    plt.figure()\n",
    "    plt.plot(test_predictions[itest, :], lw=4, ls='--', label='prediction')\n",
    "    plt.plot(test_labels[itest, :], label='truth')\n",
    "    plt.legend()\n",
    "    plt.xlabel('data index number')\n",
    "    plt.title('Normalized label values)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the 45-degree plot; close to the diagonal == good\n",
    "plt.plot((-1, 1), (-1, 1), c='r')\n",
    "plt.scatter(test_labels, test_predictions, alpha=0.3)\n",
    "plt.xlabel('truth')\n",
    "plt.ylabel('predictions')\n",
    "plt.title('Normalized label values')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'closure-1d-model.h5'\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "model_file = h5py.File(model_filename, 'r')\n",
    "\n",
    "\n",
    "def print_obj(name, obj):\n",
    "    info = ''\n",
    "    if isinstance(obj, h5py._hl.dataset.Dataset):\n",
    "        info = str(obj.shape)\n",
    "    print('{:42s} {:10s} {}'.format(name, info, type(obj)))\n",
    "\n",
    "\n",
    "model_file.visititems(print_obj)\n",
    "\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "fluid_closure_learning-1d-data_generation.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "144px",
    "left": "818px",
    "right": "20px",
    "top": "341px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
